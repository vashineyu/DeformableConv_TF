{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow import nn\n",
    "\n",
    "class DeformableConvLayer(layers.Conv2D):\n",
    "    \"\"\"Only support \"channel last\" data format\"\"\"\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 strides=(1, 1),\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1, 1),\n",
    "                 num_deformable_group=None,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"`kernel_size`, `strides` and `dilation_rate` must have the same value in both axis.\n",
    "        :param num_deformable_group: split output channels into groups, offset shared in each group. If\n",
    "        this parameter is None, then set  num_deformable_group=filters.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "        self.kernel = None\n",
    "        self.bias = None\n",
    "        self.offset_layer_kernel = None\n",
    "        self.offset_layer_bias = None\n",
    "        if num_deformable_group is None:\n",
    "            num_deformable_group = filters\n",
    "        if filters % num_deformable_group != 0:\n",
    "            raise ValueError('\"filters\" mod \"num_deformable_group\" must be zero')\n",
    "        self.num_deformable_group = num_deformable_group\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = int(input_shape[-1])\n",
    "        # kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "        # we want to use depth-wise conv\n",
    "        kernel_shape = self.kernel_size + (self.filters * input_dim, 1)\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel',\n",
    "            shape=kernel_shape,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "            trainable=True,\n",
    "            dtype=self.dtype)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                name='bias',\n",
    "                shape=(self.filters,),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "                trainable=True,\n",
    "                dtype=self.dtype)\n",
    "\n",
    "        # create offset conv layer\n",
    "        offset_num = self.kernel_size[0] * self.kernel_size[1] * self.num_deformable_group\n",
    "        print(\"offset_num: %s\" % offset_num)\n",
    "        self.offset_layer_kernel = self.add_weight(\n",
    "            name='offset_layer_kernel',\n",
    "            shape=self.kernel_size + (input_dim, offset_num * 2),  # 2 means x and y axis\n",
    "            initializer=tf.zeros_initializer(),\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            trainable=True,\n",
    "            dtype=self.dtype)\n",
    "        #print(self.offset_layer_kernel)\n",
    "        self.offset_layer_bias = self.add_weight(\n",
    "            name='offset_layer_bias',\n",
    "            shape=(offset_num * 2,),\n",
    "            initializer=tf.zeros_initializer(),\n",
    "            # initializer=tf.random_uniform_initializer(-5, 5),\n",
    "            regularizer=self.bias_regularizer,\n",
    "            trainable=True,\n",
    "            dtype=self.dtype)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        # get offset, shape [batch_size, out_h, out_w, filter_h, * filter_w * channel_out * 2]\n",
    "        offset = nn.conv2d(inputs,\n",
    "                          filter=self.offset_layer_kernel,\n",
    "                          strides=[1, *self.strides, 1],\n",
    "                          padding=self.padding.upper(),\n",
    "                          dilations=[1, *self.dilation_rate, 1])\n",
    "        # shape of offset: n_batch, feature_map_x, feature_map_y, offset_num*2\n",
    "        offset += self.offset_layer_bias\n",
    "\n",
    "        # add padding if needed\n",
    "        inputs = self._pad_input(inputs)\n",
    "\n",
    "        # some length\n",
    "        batch_size = inputs.get_shape().as_list()[0]\n",
    "        channel_in = inputs.get_shape().as_list()[-1]\n",
    "        in_h, in_w = inputs.get_shape().as_list()[1:3]  # input feature map size\n",
    "        out_h, out_w = offset.get_shape().as_list()[1:3]  # output feature map size\n",
    "        filter_h, filter_w = self.kernel_size\n",
    "\n",
    "        # get x, y axis offset\n",
    "        offset = tf.reshape(offset, [batch_size, out_h, out_w, -1, 2])\n",
    "        y_off, x_off = offset[:, :, :, :, 0], offset[:, :, :, :, 1]\n",
    "\n",
    "        # input feature map gird coordinates\n",
    "        y, x = self._get_conv_indices([in_h, in_w]) # [1, out_h, out_w, filter_h * filter_w]\n",
    "        y, x = [tf.expand_dims(i, axis=-1) for i in [y, x]]\n",
    "        y, x = [tf.tile(i, [batch_size, 1, 1, 1, self.num_deformable_group]) for i in [y, x]] # make batch_dim and filter_dim equal to kernel\n",
    "        y, x = [tf.reshape(i, [*i.shape[0: 3], -1]) for i in [y, x]]\n",
    "        y, x = [tf.to_float(i) for i in [y, x]]\n",
    "        print(y, x)\n",
    "        # add offset\n",
    "        y, x = y + y_off, x + x_off\n",
    "        y = tf.clip_by_value(y, 0, in_h - 1)\n",
    "        x = tf.clip_by_value(x, 0, in_w - 1)\n",
    "\n",
    "        # get four coordinates of points around (x, y)\n",
    "        y0, x0 = [tf.to_int32(tf.floor(i)) for i in [y, x]]\n",
    "        y1, x1 = y0 + 1, x0 + 1\n",
    "        # clip\n",
    "        y0, y1 = [tf.clip_by_value(i, 0, in_h - 1) for i in [y0, y1]]\n",
    "        x0, x1 = [tf.clip_by_value(i, 0, in_w - 1) for i in [x0, x1]]\n",
    "\n",
    "        # get pixel values\n",
    "        indices = [[y0, x0], [y0, x1], [y1, x0], [y1, x1]]\n",
    "        p0, p1, p2, p3 = [self._get_pixel_values_at_point(inputs, i) for i in indices]\n",
    "        # cast to float\n",
    "        x0, x1, y0, y1 = [tf.to_float(i) for i in [x0, x1, y0, y1]]\n",
    "        # weights\n",
    "        w0 = (y1 - y) * (x1 - x)\n",
    "        w1 = (y1 - y) * (x - x0)\n",
    "        w2 = (y - y0) * (x1 - x)\n",
    "        w3 = (y - y0) * (x - x0)\n",
    "        # expand dim for broadcast\n",
    "        w0, w1, w2, w3 = [tf.expand_dims(i, axis=-1) for i in [w0, w1, w2, w3]]\n",
    "        # bilinear interpolation\n",
    "        pixels = tf.add_n([w0 * p0, w1 * p1, w2 * p2, w3 * p3])\n",
    "\n",
    "        # reshape the \"big\" feature map\n",
    "        pixels = tf.reshape(pixels, [batch_size, out_h, out_w, filter_h, filter_w, self.num_deformable_group, channel_in])\n",
    "        pixels = tf.transpose(pixels, [0, 1, 3, 2, 4, 5, 6])\n",
    "        pixels = tf.reshape(pixels, [batch_size, out_h * filter_h, out_w * filter_w, self.num_deformable_group, channel_in])\n",
    "\n",
    "        # copy channels to same group\n",
    "        feat_in_group = self.filters // self.num_deformable_group\n",
    "        pixels = tf.tile(pixels, [1, 1, 1, 1, feat_in_group])\n",
    "        pixels = tf.reshape(pixels, [batch_size, out_h * filter_h, out_w * filter_w, -1])\n",
    "\n",
    "        # depth-wise conv\n",
    "        out = tf.nn.depthwise_conv2d(pixels, self.kernel, [1, filter_h, filter_w, 1], 'VALID')\n",
    "        # add the output feature maps in the same group\n",
    "        out = tf.reshape(out, [batch_size, out_h, out_w, self.filters, channel_in])\n",
    "        out = tf.reduce_sum(out, axis=-1)\n",
    "        if self.use_bias:\n",
    "            out += self.bias\n",
    "        return self.activation(out)\n",
    "\n",
    "    def _pad_input(self, inputs):\n",
    "        \"\"\"Check if input feature map needs padding, because we don't use the standard Conv() function.\n",
    "        :param inputs:\n",
    "        :return: padded input feature map\n",
    "        \"\"\"\n",
    "        # When padding is 'same', we should pad the feature map.\n",
    "        # if padding == 'same', output size should be `ceil(input / stride)`\n",
    "        if self.padding == 'same':\n",
    "            in_shape = inputs.get_shape().as_list()[1: 3]\n",
    "            padding_list = []\n",
    "            for i in range(2):\n",
    "                filter_size = self.kernel_size[i]\n",
    "                dilation = self.dilation_rate[i]\n",
    "                dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n",
    "                same_output = (in_shape[i] + self.strides[i] - 1) // self.strides[i]\n",
    "                valid_output = (in_shape[i] - dilated_filter_size + self.strides[i]) // self.strides[i]\n",
    "                if same_output == valid_output:\n",
    "                    padding_list += [0, 0]\n",
    "                else:\n",
    "                    p = dilated_filter_size - 1\n",
    "                    p_0 = p // 2\n",
    "                    padding_list += [p_0, p - p_0]\n",
    "            if sum(padding_list) != 0:\n",
    "                padding = [[0, 0],\n",
    "                           [padding_list[0], padding_list[1]],  # top, bottom padding\n",
    "                           [padding_list[2], padding_list[3]],  # left, right padding\n",
    "                           [0, 0]]\n",
    "                inputs = tf.pad(inputs, padding)\n",
    "        return inputs\n",
    "\n",
    "    def _get_conv_indices(self, feature_map_size):\n",
    "        \"\"\"the x, y coordinates in the window when a filter sliding on the feature map\n",
    "        :param feature_map_size:\n",
    "        :return: y, x with shape [1, out_h, out_w, filter_h * filter_w]\n",
    "        \"\"\"\n",
    "        feat_h, feat_w = [int(i) for i in feature_map_size[0: 2]]\n",
    "\n",
    "        x, y = tf.meshgrid(tf.range(feat_w), tf.range(feat_h)) # shape: 2d, x: h*w, y: h*w\n",
    "        # reshape meshgrid into 1,h,w,1\n",
    "        x, y = [tf.reshape(i, [1, *i.get_shape(), 1]) for i in [x, y]]  # shape: 4d, [1, h, w, 1]\n",
    "        x, y = [tf.image.extract_image_patches(i,\n",
    "                                               [1, *self.kernel_size, 1],\n",
    "                                               [1, *self.strides, 1],\n",
    "                                               [1, *self.dilation_rate, 1],\n",
    "                                               'VALID')\n",
    "                for i in [x, y]]  # shape [1, out_h, out_w, filter_h * filter_w]\n",
    "        return y, x\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_pixel_values_at_point(inputs, indices):\n",
    "        \"\"\"get pixel values\n",
    "        :param inputs:\n",
    "        :param indices: shape [batch_size, H, W, I], I = filter_h * filter_w * channel_out\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        y, x = indices\n",
    "        batch, h, w, n = y.get_shape().as_list()[0: 4]\n",
    "\n",
    "        batch_idx = tf.reshape(tf.range(0, batch), (batch, 1, 1, 1))\n",
    "        b = tf.tile(batch_idx, (1, h, w, n))\n",
    "        pixel_idx = tf.stack([b, y, x], axis=-1)\n",
    "        return tf.gather_nd(inputs, pixel_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 10]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a = tf.Variable(np.random.random((16,10,10,3)), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset_num: 288\n",
      "Tensor(\"deformable_conv_layer_14/ToFloat:0\", shape=(16, 8, 8, 288), dtype=float32) Tensor(\"deformable_conv_layer_14/ToFloat_1:0\", shape=(16, 8, 8, 288), dtype=float32)\n",
      "Tensor(\"deformable_conv_layer_14/GatherNd:0\", shape=(16, 8, 8, 288, 3), dtype=float32) Tensor(\"deformable_conv_layer_14/GatherNd_1:0\", shape=(16, 8, 8, 288, 3), dtype=float32) Tensor(\"deformable_conv_layer_14/GatherNd_2:0\", shape=(16, 8, 8, 288, 3), dtype=float32) Tensor(\"deformable_conv_layer_14/GatherNd_3:0\", shape=(16, 8, 8, 288, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "deformabe_layer = DeformableConvLayer(filters=32,kernel_size=3)(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'deformable_conv_layer_6/add_5:0' shape=(16, 8, 8, 32) dtype=float32>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deformabe_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input shape: [batch, in_height, in_width, in_channels]\n",
    "#filter shape: [filter_height, filter_width, in_channels, out_channels]\n",
    "nn.conv2d(input=a, filter="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "\n",
    "def preproc_fn(x):\n",
    "    return x / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# train.py / main\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from config import get_cfg_defaults\n",
    "cfg = get_cfg_defaults()\n",
    "\n",
    "devices = \",\".join(str(i) for i in cfg.SYSTEM.DEVICES)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = devices\n",
    "\n",
    "from dataloader import GetDataset, DataLoader, TrainingAugmentation, TestingAugmentation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "\n",
    "trainset, testset = load_data()\n",
    "x_train, y_train = trainset\n",
    "x_test, y_test = testset\n",
    "\n",
    "idx = np.arange(len(x_train))\n",
    "idx_train, idx_valid = train_test_split(idx, test_size=0.1)\n",
    "x_train, x_valid = x_train[idx_train], x_train[idx_valid]\n",
    "y_train, y_valid = y_train[idx_train], y_train[idx_valid]\n",
    "\n",
    "dataset_train = GetDataset(x=x_train, y=y_train, num_classes=10, \n",
    "                           preproc_fn=preproc_fn, augment_fn=TrainingAugmentation.augmentation)\n",
    "dataset_valid = GetDataset(x=x_valid, y=y_valid, num_classes=10, \n",
    "                           preproc_fn=preproc_fn, augment_fn=TestingAugmentation.augmentation)\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset_train, batch_size=cfg.MODEL.BATCH_SIZE)\n",
    "\n",
    "x_valid, y_valid = next(iter(DataLoader(dataset_valid, batch_size=len(dataset_valid))))\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
