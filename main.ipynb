{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow import nn\n",
    "\n",
    "class DeformableConvLayer(layers.Conv2D):\n",
    "    \"\"\"Only support \"channel last\" data format\"\"\"\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 strides=(1, 1),\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1, 1),\n",
    "                 num_deformable_group=None,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"`kernel_size`, `strides` and `dilation_rate` must have the same value in both axis.\n",
    "        :param num_deformable_group: split output channels into groups, offset shared in each group. If\n",
    "        this parameter is None, then set  num_deformable_group=filters.\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "        self.kernel = None\n",
    "        self.bias = None\n",
    "        self.offset_layer_kernel = None\n",
    "        self.offset_layer_bias = None\n",
    "        if num_deformable_group is None:\n",
    "            num_deformable_group = filters\n",
    "        if filters % num_deformable_group != 0:\n",
    "            raise ValueError('\"filters\" mod \"num_deformable_group\" must be zero')\n",
    "        self.num_deformable_group = num_deformable_group\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = int(input_shape[-1])\n",
    "        #kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "        # we want to use depth-wise conv\n",
    "        kernel_shape = self.kernel_size + (self.filters * input_dim, 1)\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel',\n",
    "            shape=kernel_shape,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "            trainable=True,\n",
    "            dtype=self.dtype)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                name='bias',\n",
    "                shape=(self.filters,),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "                trainable=True,\n",
    "                dtype=self.dtype)\n",
    "\n",
    "        # create offset conv layer\n",
    "        offset_num = self.kernel_size[0] * self.kernel_size[1] * self.num_deformable_group\n",
    "        #print(\"offset_num: %s\" % offset_num)\n",
    "        self.offset_layer_kernel = self.add_weight(\n",
    "            name='offset_layer_kernel',\n",
    "            shape=self.kernel_size + (input_dim, offset_num * 2),  # 2 means x and y axis\n",
    "            initializer=tf.zeros_initializer(),\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            trainable=True,\n",
    "            dtype=self.dtype)\n",
    "        #print(self.offset_layer_kernel)\n",
    "        self.offset_layer_bias = self.add_weight(\n",
    "            name='offset_layer_bias',\n",
    "            shape=(offset_num * 2,),\n",
    "            initializer=tf.zeros_initializer(),\n",
    "            # initializer=tf.random_uniform_initializer(-5, 5),\n",
    "            regularizer=self.bias_regularizer,\n",
    "            trainable=True,\n",
    "            dtype=self.dtype)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        # get offset, shape [batch_size, out_h, out_w, filter_h, * filter_w * channel_out * 2]\n",
    "        offset = nn.conv2d(inputs,\n",
    "                          filter=self.offset_layer_kernel,\n",
    "                          strides=[1, *self.strides, 1],\n",
    "                          padding=self.padding.upper(),\n",
    "                          dilations=[1, *self.dilation_rate, 1])\n",
    "        # shape of offset: n_batch, feature_map_x, feature_map_y, offset_num*2\n",
    "        offset += self.offset_layer_bias\n",
    "\n",
    "        # add padding if needed\n",
    "        inputs = self._pad_input(inputs)\n",
    "\n",
    "        # some length\n",
    "        batch_size = K.shape(offset)[0]\n",
    "        #offset_size = int(offset.get_shape().as_list()[-1] / 2)\n",
    "        channel_in = inputs.get_shape().as_list()[-1]\n",
    "        in_h, in_w = inputs.get_shape().as_list()[1:3]  # input feature map size\n",
    "        out_h, out_w = offset.get_shape().as_list()[1:3]  # output feature map size\n",
    "        filter_h, filter_w = self.kernel_size\n",
    "\n",
    "        # get x, y axis offset\n",
    "        offset = tf.reshape(offset, [batch_size, out_h, out_w, -1, 2])\n",
    "        y_off, x_off = offset[:, :, :, :, 0], offset[:, :, :, :, 1]\n",
    "\n",
    "        # input feature map gird coordinates\n",
    "        y, x = self._get_conv_indices([in_h, in_w]) # [1, out_h, out_w, filter_h*filter_w]\n",
    "        y, x = [tf.expand_dims(i, axis=-1) for i in [y, x]]\n",
    "        \n",
    "        y, x = [tf.tile(i, [batch_size, 1, 1, 1, self.num_deformable_group]) for i in [y, x]] # make batch_dim and filter_dim equal to kernel\n",
    "        y, x = [tf.reshape(i, [K.shape(i)[0], *i.shape[1: 3], filter_h*filter_w*self.num_deformable_group]) for i in [y, x]]\n",
    "        print(y)\n",
    "        y, x = [tf.to_float(i) for i in [y, x]]\n",
    "        \n",
    "        # print(y, x)\n",
    "        # add offset\n",
    "        y, x = y + y_off, x + x_off\n",
    "        y = tf.clip_by_value(y, 0, in_h - 1)\n",
    "        x = tf.clip_by_value(x, 0, in_w - 1)\n",
    "\n",
    "        # get four coordinates of points around (x, y)\n",
    "        y0, x0 = [tf.to_int32(tf.floor(i)) for i in [y, x]]\n",
    "        y1, x1 = y0 + 1, x0 + 1\n",
    "        # clip\n",
    "        y0, y1 = [tf.clip_by_value(i, 0, in_h - 1) for i in [y0, y1]]\n",
    "        x0, x1 = [tf.clip_by_value(i, 0, in_w - 1) for i in [x0, x1]]\n",
    "\n",
    "        # get pixel values\n",
    "        indices = [[y0, x0], [y0, x1], [y1, x0], [y1, x1]]\n",
    "        p0, p1, p2, p3 = [self._get_pixel_values_at_point(inputs, i) for i in indices]\n",
    "        # cast to float\n",
    "        x0, x1, y0, y1 = [tf.to_float(i) for i in [x0, x1, y0, y1]]\n",
    "        # weights\n",
    "        w0 = (y1 - y) * (x1 - x)\n",
    "        w1 = (y1 - y) * (x - x0)\n",
    "        w2 = (y - y0) * (x1 - x)\n",
    "        w3 = (y - y0) * (x - x0)\n",
    "        # expand dim for broadcast\n",
    "        w0, w1, w2, w3 = [tf.expand_dims(i, axis=-1) for i in [w0, w1, w2, w3]]\n",
    "        # bilinear interpolation\n",
    "        pixels = tf.add_n([w0 * p0, w1 * p1, w2 * p2, w3 * p3])\n",
    "        \n",
    "        ### ==== ###\n",
    "        \"\"\"\n",
    "        print(pixels)\n",
    "        pixels = self._rebuild_shape_to_batch(pixels)\n",
    "        print(pixels)\n",
    "        \"\"\"\n",
    "        ### ==== ###\n",
    "\n",
    "        # reshape the \"big\" feature map\n",
    "        pixels = tf.reshape(pixels, [batch_size, out_h, out_w, filter_h, filter_w, self.num_deformable_group, channel_in])\n",
    "        pixels = tf.transpose(pixels, [0, 1, 3, 2, 4, 5, 6])\n",
    "        pixels = tf.reshape(pixels, [batch_size, out_h * filter_h, out_w * filter_w, self.num_deformable_group, channel_in])\n",
    "\n",
    "        # copy channels to same group\n",
    "        feat_in_group = self.filters // self.num_deformable_group\n",
    "        pixels = tf.tile(pixels, [1, 1, 1, 1, feat_in_group])\n",
    "        pixels = tf.reshape(pixels, [batch_size, out_h * filter_h, out_w * filter_w, -1])\n",
    "\n",
    "        # depth-wise conv\n",
    "        out = tf.nn.depthwise_conv2d(pixels, self.kernel, [1, filter_h, filter_w, 1], 'VALID')\n",
    "        # add the output feature maps in the same group\n",
    "        out = tf.reshape(out, [-1, out_h, out_w, self.filters, channel_in])\n",
    "        out = tf.reduce_sum(out, axis=-1)\n",
    "        if self.use_bias:\n",
    "            out += self.bias\n",
    "        return self.activation(out)\n",
    "\n",
    "    def _pad_input(self, inputs):\n",
    "        \"\"\"Check if input feature map needs padding, because we don't use the standard Conv() function.\n",
    "        :param inputs:\n",
    "        :return: padded input feature map\n",
    "        \"\"\"\n",
    "        # When padding is 'same', we should pad the feature map.\n",
    "        # if padding == 'same', output size should be `ceil(input / stride)`\n",
    "        if self.padding == 'same':\n",
    "            in_shape = inputs.get_shape().as_list()[1: 3]\n",
    "            padding_list = []\n",
    "            for i in range(2):\n",
    "                filter_size = self.kernel_size[i]\n",
    "                dilation = self.dilation_rate[i]\n",
    "                dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\n",
    "                same_output = (in_shape[i] + self.strides[i] - 1) // self.strides[i]\n",
    "                valid_output = (in_shape[i] - dilated_filter_size + self.strides[i]) // self.strides[i]\n",
    "                if same_output == valid_output:\n",
    "                    padding_list += [0, 0]\n",
    "                else:\n",
    "                    p = dilated_filter_size - 1\n",
    "                    p_0 = p // 2\n",
    "                    padding_list += [p_0, p - p_0]\n",
    "            if sum(padding_list) != 0:\n",
    "                padding = [[0, 0],\n",
    "                           [padding_list[0], padding_list[1]],  # top, bottom padding\n",
    "                           [padding_list[2], padding_list[3]],  # left, right padding\n",
    "                           [0, 0]]\n",
    "                inputs = tf.pad(inputs, padding)\n",
    "        return inputs\n",
    "\n",
    "    def _get_conv_indices(self, feature_map_size):\n",
    "        \"\"\"the x, y coordinates in the window when a filter sliding on the feature map\n",
    "        :param feature_map_size:\n",
    "        :return: y, x with shape [1, out_h, out_w, filter_h * filter_w]\n",
    "        \"\"\"\n",
    "        feat_h, feat_w = [int(i) for i in feature_map_size[0: 2]]\n",
    "\n",
    "        x, y = tf.meshgrid(tf.range(feat_w), tf.range(feat_h)) # shape: 2d, x: h*w, y: h*w\n",
    "        # reshape meshgrid into 1,h,w,1\n",
    "        x, y = [tf.reshape(i, [1, *i.get_shape(), 1]) for i in [x, y]]  # shape: 4d, [1, h, w, 1]\n",
    "        x, y = [tf.image.extract_image_patches(i,\n",
    "                                               [1, *self.kernel_size, 1],\n",
    "                                               [1, *self.strides, 1],\n",
    "                                               [1, *self.dilation_rate, 1],\n",
    "                                               'VALID')\n",
    "                for i in [x, y]]  # shape [1, out_h, out_w, filter_h * filter_w]\n",
    "        return y, x\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_pixel_values_at_point(inputs, indices):\n",
    "        \"\"\"get pixel values\n",
    "        :param inputs:\n",
    "        :param indices: shape [batch_size, H, W, I], I = filter_h * filter_w * channel_out\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        y, x = indices\n",
    "        batch, h, w, n = y.get_shape().as_list()[0: 4]\n",
    "        #batch = 32 if batch is None else batch\n",
    "        batch = K.shape(y)[0]\n",
    "\n",
    "        batch_idx = tf.reshape(tf.range(0, batch), (batch, 1, 1, 1))\n",
    "        b = tf.tile(batch_idx, (1, h, w, n))\n",
    "        pixel_idx = tf.stack([b, y, x], axis=-1)\n",
    "        return tf.gather_nd(inputs, pixel_idx)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _rebuild_shape_to_batch(tensor_to_rebuild):\n",
    "        \"\"\"In _get_pixel_values_at_point, batch dimension has already been set to stablize graph,\n",
    "        We convert it back to None for batch dim\n",
    "        \"\"\"\n",
    "        new_shape = tf.TensorShape([None]).concatenate(tensor_to_rebuild.get_shape()[1:])\n",
    "        output = tf.placeholder_with_default(tensor_to_rebuild, shape=new_shape)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_pooling2d_2/MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "(3, 3, 2048, 1)\n",
      "288\n",
      "a Tensor(\"deformable_conv_layer_35/Tile_6:0\", shape=(?, 42, 42, 64, 32), dtype=float32)\n",
      "32\n",
      "b Tensor(\"deformable_conv_layer_35/Reshape_11:0\", shape=(?, 42, 42, ?), dtype=float32)\n",
      "Tensor(\"deformable_conv_layer_35/Reshape_11:0\", shape=(?, 42, 42, ?), dtype=float32)\n",
      "<tf.Variable 'deformable_conv_layer_35/kernel:0' shape=(3, 3, 2048, 1) dtype=float32>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nx = layers.BatchNormalization(axis=-1)(x)\\nx = layers.Activation(\"relu\")(x)\\nx = layers.MaxPooling2D(pool_size=2)(x)\\n\\nif use_deformable:\\n    x = DeformableConvLayer(filters=64, kernel_size=3, strides=(1,1), padding=\"same\")(x)\\nelse:\\n    x = layers.Conv2D(filters=64, kernel_size=3, strides=(1,1), padding=\"same\")(x)\\nx = layers.BatchNormalization(axis=-1)(x)\\nx = layers.Activation(\"relu\")(x)\\nx = layers.GlobalAveragePooling2D()(x)\\n\\nout = layers.Dense(units=output_num, activation=\"softmax\")(x)\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.py\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras import layers\n",
    "\n",
    "\n",
    "input_layer = layers.Input(shape=(28,28,1), dtype=tf.float32)\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, strides=(1,1), padding=\"same\")(input_layer)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "print(x)\n",
    "x = DeformableConvLayer(filters=64, kernel_size=3, strides=(1,1), padding=\"same\")(x)\n",
    "\n",
    "#x = layers.Conv2D(filters=64, kernel_size=3, strides=(1,1), padding=\"same\")(x)\n",
    "\"\"\"\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "if use_deformable:\n",
    "    x = DeformableConvLayer(filters=64, kernel_size=3, strides=(1,1), padding=\"same\")(x)\n",
    "else:\n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, strides=(1,1), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization(axis=-1)(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "out = layers.Dense(units=output_num, activation=\"softmax\")(x)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'strided_slice_2:0' shape=() dtype=int32>,\n",
       " Dimension(28),\n",
       " Dimension(28),\n",
       " -1]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[K.shape(a)[0], *a.shape[1: 3], -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"deformable_conv_layer_8/Tile:0\", shape=(?, 28, 28, 9, 32), dtype=int32)\n",
      "3 3 16 32\n",
      "Tensor(\"deformable_conv_layer_8/Reshape_3:0\", shape=(?, 28, 28, 144), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.keras.layers.Input((28, 28, 16), dtype=tf.float32)\n",
    "#a = tf.Variable(np.random.random((128, 28, 28, 1)), dtype=tf.float32)\n",
    "b = DeformableConvLayer(filters=32, kernel_size=3, padding=\"same\")(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'deformable_conv_layer_20/add_5:0' shape=(128, 26, 26, 32) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor(\"deformable_conv_layer_39/ToFloat:0\", shape=(1, 28, 28, 288), dtype=float32)\n",
    "a Tensor(\"deformable_conv_layer_39/Tile_6:0\", shape=(128, 84, 84, 32, 1), dtype=float32)\n",
    "b Tensor(\"deformable_conv_layer_39/Reshape_11:0\", shape=(128, 84, 84, 32), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'deformable_conv_layer_53/add_5:0' shape=(?, 28, 28, 32) dtype=float32>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_shape = tf.TensorShape([None]).concatenate(b.get_shape()[1:])\n",
    "#b = tf.placeholder_with_default(b, shape=new_shape)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# train.py / main\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import get_cfg_defaults\n",
    "from DeformableConv_TF.model import preproc_fn, build_model\n",
    "cfg = get_cfg_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.USE_DEFORMABLE_CONV = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "devices = \",\".join(str(i) for i in cfg.SYSTEM.DEVICES)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = devices\n",
    "\n",
    "from dataloader import GetDataset, DataLoader, TrainingAugmentation, TestingAugmentation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "\n",
    "trainset, testset = load_data()\n",
    "x_train, y_train = trainset\n",
    "x_test, y_test = testset\n",
    "\n",
    "idx = np.arange(len(x_train))\n",
    "idx_train, idx_valid = train_test_split(idx, test_size=0.1)\n",
    "x_train, x_valid = x_train[idx_train], x_train[idx_valid]\n",
    "y_train, y_valid = y_train[idx_train], y_train[idx_valid]\n",
    "\n",
    "dataset_train = GetDataset(x=x_train, y=y_train, num_classes=10, \n",
    "                           preproc_fn=preproc_fn, augment_fn=TrainingAugmentation.augmentation)\n",
    "dataset_valid = GetDataset(x=x_valid, y=y_valid, num_classes=10, \n",
    "                           preproc_fn=preproc_fn, augment_fn=TestingAugmentation.augmentation)\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset_train, batch_size=cfg.MODEL.BATCH_SIZE)\n",
    "\n",
    "x_valid, y_valid = next(iter(DataLoader(dataset_valid, batch_size=len(dataset_valid))))\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a Tensor(\"deformable_conv_layer/Tile_6:0\", shape=(?, 42, 42, 64, 32), dtype=float32)\n",
      "32\n",
      "b Tensor(\"deformable_conv_layer/Reshape_11:0\", shape=(?, 42, 42, ?), dtype=float32)\n",
      "Tensor(\"deformable_conv_layer/Reshape_11:0\", shape=(?, 42, 42, ?), dtype=float32)\n",
      "<tf.Variable 'deformable_conv_layer/kernel:0' shape=(3, 3, 2048, 1) dtype=float32>\n",
      "a Tensor(\"deformable_conv_layer_1/Tile_6:0\", shape=(?, 21, 21, 64, 64), dtype=float32)\n",
      "64\n",
      "b Tensor(\"deformable_conv_layer_1/Reshape_11:0\", shape=(?, 21, 21, ?), dtype=float32)\n",
      "Tensor(\"deformable_conv_layer_1/Reshape_11:0\", shape=(?, 21, 21, ?), dtype=float32)\n",
      "<tf.Variable 'deformable_conv_layer_1/kernel:0' shape=(3, 3, 4096, 1) dtype=float32>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "deformable_conv_layer (Defor (None, 14, 14, 64)        351424    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "deformable_conv_layer_1 (Def (None, 7, 7, 64)          701632    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,054,666\n",
      "Trainable params: 1,054,346\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(input_shape=x_valid.shape[1:], output_num=y_valid.shape[-1], use_deformable=cfg.MODEL.USE_DEFORMABLE_CONV)\n",
    "optim = tf.keras.optimizers.SGD(lr=cfg.MODEL.LEARNING_RATE, nesterov=True, momentum=0.95)\n",
    "#optim = tf.keras.optimizers.Adam(lr=cfg.MODEL.LEARNING_RATE)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"acc\"], optimizer=optim)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/211 [..............................] - ETA: 1:47:36 - loss: 2.3371 - acc: 0.1348"
     ]
    }
   ],
   "source": [
    "model.fit_generator(dataloader, \n",
    "                    epochs=cfg.MODEL.EPOCHS, \n",
    "                    steps_per_epoch=len(dataloader), \n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14450688 / 32 / 9 / 28 / 28"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
